% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/start_pipline.R
\name{start_pipeline}
\alias{start_pipeline}
\title{Run the Full Stock Data ETL Pipeline (Database Focused)}
\usage{
start_pipeline(
  batch_size = 50,
  symbol_table_name = "sp500",
  symbol_col_name = "symbol",
  data_table_name = "data_sp500",
  log_table_name = "pipeline_logs",
  date_from,
  date_to = Sys.Date(),
  db_connection = NULL
)
}
\arguments{
\item{batch_size}{Integer. Max symbols per API call batch. Defaults to 50.}

\item{symbol_table_name}{Character string. DB table containing symbols. Defaults to "sp500".}

\item{symbol_col_name}{Character string. Column name for symbols in symbol table. Defaults to "symbol".}

\item{data_table_name}{Character string. Main DB table for stock data. Defaults to "data_sp500".}

\item{log_table_name}{Character string. DB table for logs. Defaults to "pipeline_logs".}

\item{date_from}{Character string or Date. Start date for fetching data. Required.}

\item{date_to}{Character string or Date. End date for fetching data. Defaults to \code{Sys.Date()}.}

\item{db_connection}{Optional. An existing DBI connection. If NULL (default),
\code{connect_db()} is called internally and disconnected upon exit.}
}
\value{
Invisibly returns the final log data frame.
}
\description{
Orchestrates the process: connects to DB, fetches symbols from DB,
processes in batches to get Yahoo data, formats, inserts new records into data table,
logs results, and pushes logs to DB.
}
\examples{
\dontrun{
# Ensure env vars for connect_db() are set.
# Ensure DB tables (sp500, data_sp500, pipeline_logs) exist.
final_logs <- start_pipeline(date_from = Sys.Date() - 7)
print(final_logs)
}
}
